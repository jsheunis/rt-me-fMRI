{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports and file/directory setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from os import remove\n",
    "from os.path import join, splitext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from convert_eprime.utils import remove_unicode\n",
    "from convert_eprime.convert import text_to_csv\n",
    "\n",
    "data_dir = '/Volumes/Stephan_WD/NEUFEPME_data/'\n",
    "org_data_dir = '/Volumes/Stephan_WD/NEUFEPME_data_organised/'\n",
    "bids_data_dir = '/Volumes/Stephan_WD/NEUFEPME_data_BIDS/'\n",
    "eprime_data_dir = '/Volumes/Stephan_WD/NEUFEPME_data_eprime/'\n",
    "\n",
    "os.chdir(bids_data_dir)\n",
    "all_subs = next(os.walk(bids_data_dir))[1]\n",
    "sub = '012'\n",
    "sub_data_dir = eprime_data_dir + 'sub-' + sub\n",
    "txt_files = [None] * 4\n",
    "paradigms = ['motor-', 'motor-imagine-', 'emotion-', 'emotion-imagine-']\n",
    "paradigm_nrs = ['-001', '-002', '-001', '-002']\n",
    "csv_files = [None] * 4\n",
    "event_files = [None] * 4\n",
    "for i, par in enumerate(paradigms):\n",
    "    txt_files[i] = join(sub_data_dir, 'neufepme-' + par + sub + paradigm_nrs[i] + '.txt')\n",
    "    name, ext = splitext(txt_files[i])\n",
    "    csv_files[i] = name + '.csv'\n",
    "    event_files[i] = name + '_events.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read text files, convert to csv files, and load dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file successfully created- /Volumes/Stephan_WD/NEUFEPME_data_eprime/sub-012/neufepme-motor-012-001.csv\n",
      "Output file successfully created- /Volumes/Stephan_WD/NEUFEPME_data_eprime/sub-012/neufepme-motor-imagine-012-002.csv\n",
      "Output file successfully created- /Volumes/Stephan_WD/NEUFEPME_data_eprime/sub-012/neufepme-emotion-012-001.csv\n",
      "Output file successfully created- /Volumes/Stephan_WD/NEUFEPME_data_eprime/sub-012/neufepme-emotion-imagine-012-002.csv\n"
     ]
    }
   ],
   "source": [
    "all_dfs = {}\n",
    "for i, fn in enumerate(txt_files):\n",
    "    text_to_csv(fn, csv_files[i])\n",
    "    df = pd.read_csv(csv_files[i])\n",
    "    all_dfs[paradigms[i]] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Extract necessary data from dataframes, reorder into sensible blocks, write to text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Motor, motor-imagine, and emotion-imagine (same structure or eprime files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Description  of data to extract:\n",
    "# Rows 0:9 (including 9) - ['Rest.OnsetTime', 'Rest.OnsetToOnsetTime', 'Tap.OnsetTime']\n",
    "# Row 10 - ['LastRest.OnsetTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tapping\n",
      "       type     onset\n",
      "0      rest   69205.0\n",
      "1   tapping   89218.0\n",
      "2      rest  109230.0\n",
      "3   tapping  129243.0\n",
      "4      rest  149256.0\n",
      "5   tapping  169268.0\n",
      "6      rest  189281.0\n",
      "7   tapping  209294.0\n",
      "8      rest  229306.0\n",
      "9   tapping  249319.0\n",
      "10     rest  269332.0\n",
      "11  tapping  289345.0\n",
      "12     rest  309357.0\n",
      "13  tapping  329370.0\n",
      "14     rest  349383.0\n",
      "15  tapping  369395.0\n",
      "16     rest  389408.0\n",
      "17  tapping  409421.0\n",
      "18     rest  429433.0\n",
      "19  tapping  449446.0\n",
      "20     rest  469459.0\n",
      "mental-tapping\n",
      "              type     onset\n",
      "0             rest   67815.0\n",
      "1   mental-tapping   87827.0\n",
      "2             rest  107840.0\n",
      "3   mental-tapping  127853.0\n",
      "4             rest  147865.0\n",
      "5   mental-tapping  167878.0\n",
      "6             rest  187891.0\n",
      "7   mental-tapping  207903.0\n",
      "8             rest  227916.0\n",
      "9   mental-tapping  247929.0\n",
      "10            rest  267941.0\n",
      "11  mental-tapping  287954.0\n",
      "12            rest  307967.0\n",
      "13  mental-tapping  327979.0\n",
      "14            rest  347992.0\n",
      "15  mental-tapping  368005.0\n",
      "16            rest  388017.0\n",
      "17  mental-tapping  408030.0\n",
      "18            rest  428043.0\n",
      "19  mental-tapping  448055.0\n",
      "20            rest  468068.0\n",
      "mental-emotion\n",
      "              type     onset\n",
      "0             rest   51714.0\n",
      "1   mental-emotion   71727.0\n",
      "2             rest   91740.0\n",
      "3   mental-emotion  111752.0\n",
      "4             rest  131765.0\n",
      "5   mental-emotion  151778.0\n",
      "6             rest  171790.0\n",
      "7   mental-emotion  191803.0\n",
      "8             rest  211816.0\n",
      "9   mental-emotion  231828.0\n",
      "10            rest  251841.0\n",
      "11  mental-emotion  271854.0\n",
      "12            rest  291866.0\n",
      "13  mental-emotion  311879.0\n",
      "14            rest  331892.0\n",
      "15  mental-emotion  351904.0\n",
      "16            rest  371917.0\n",
      "17  mental-emotion  391930.0\n",
      "18            rest  411943.0\n",
      "19  mental-emotion  431955.0\n",
      "20            rest  451968.0\n"
     ]
    }
   ],
   "source": [
    "# paradigms = ['motor-', 'motor-imagine-', 'emotion-', 'emotion-imagine-']\n",
    "\n",
    "task = ['tapping', 'mental-tapping', '', 'mental-emotion']\n",
    "\n",
    "for p in [0,1,3]:    \n",
    "    df = all_dfs[paradigms[p]]\n",
    "    # print(df)\n",
    "    columns = ['type', 'onset']\n",
    "    events_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for i in np.arange(10):\n",
    "        events_df = events_df.append({'type': 'rest', 'onset': df.loc[i, 'Rest.OnsetTime']}, ignore_index=True)\n",
    "        events_df = events_df.append({'type': task[p], 'onset': df.loc[i, 'Tap.OnsetTime']}, ignore_index=True)\n",
    "\n",
    "    events_df = events_df.append({'type': 'rest', 'onset': df.loc[10, 'LastRest.OnsetTime']}, ignore_index=True)\n",
    "    \n",
    "    events_df.to_csv(event_files[p], index=False)\n",
    "    print(task[p])\n",
    "    print(events_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Description  of data to extract:\n",
    "\n",
    "# { Cue+Match(shape)+5*[ITI+Match(shape)] + Cue+Match(face)+5*[ITI+Match(face)] }*10 + Cue+Match(shape)+5*[ITI+Match(shape)]\n",
    "\n",
    "# --0--\n",
    "# 0-4 = ShapeTaskList:ShapesDisplay.OnsetToOnsetTime\n",
    "# 5 = ShapesList:Shape.OnsetToOnsetTime\n",
    "# 6-10 = FaceTaskList:FacesDisplay.OnsetToOnsetTime\n",
    "# 11 = FacesList:Face.OnsetToOnsetTime\n",
    "# --1--\n",
    "# 12-16 = ShapeTaskList1:ShapesDisplay1.OnsetToOnsetTime\n",
    "# 17 = ShapesList1:Shape1.OnsetToOnsetTime\n",
    "# 18-22 = FaceTaskList1:FacesDisplay1.OnsetToOnsetTime\n",
    "# 23 = FacesList1:Face1.OnsetToOnsetTime\n",
    "# --2--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Extract interpretable blocks\n",
    "\n",
    "df = all_dfs[paradigms[2]]\n",
    "all_blocks = {}\n",
    "\n",
    "for i in np.arange(11):\n",
    "    loc1 = i*12\n",
    "    loc2 = loc1+4\n",
    "    loc3 = loc2+1\n",
    "    loc4 = loc3+1\n",
    "    loc5 = loc4+4\n",
    "    loc6 = loc5+1\n",
    "    \n",
    "    all_blocks[i] = {}\n",
    "    \n",
    "    if i == 0:\n",
    "        txt = ''\n",
    "    else:\n",
    "        txt = str(i)\n",
    "    \n",
    "    marker1a = 'ShapeTaskList' + txt\n",
    "    marker1b = 'ShapesDisplay' + txt + '.OnsetToOnsetTime'\n",
    "    marker2a = 'ShapesList' + txt\n",
    "    marker2b = 'Shape' + txt + '.OnsetToOnsetTime'\n",
    "    marker3a = 'FaceTaskList' + txt\n",
    "    marker3b = 'FacesDisplay' + txt + '.OnsetToOnsetTime'\n",
    "    marker4a = 'FacesList' + txt\n",
    "    marker4b = 'Face' + txt + '.OnsetToOnsetTime'\n",
    "    \n",
    "    if i < 10:\n",
    "        all_blocks[i]['shape1'] = df.loc[loc3, marker2a:marker2b]\n",
    "        all_blocks[i]['shape5'] = df.loc[loc1:loc2, marker1a:marker1b]\n",
    "        all_blocks[i]['face1'] = df.loc[loc6, marker4a:marker4b]\n",
    "        all_blocks[i]['face5'] = df.loc[loc4:loc5, marker3a:marker3b]\n",
    "    else:        \n",
    "        all_blocks[i]['shape1'] = df.loc[loc3, marker2a:marker2b]\n",
    "        all_blocks[i]['shape5'] = df.loc[loc1:loc2, marker1a:marker1b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapesList                        1\n",
      "Stimulus                        NaN\n",
      "ShapesList.Cycle                  1\n",
      "ShapesList.Sample                 1\n",
      "ShapesCue.OnsetDelay             17\n",
      "ShapesCue.OnsetTime           81852\n",
      "ShapesCue.DurationError           0\n",
      "ShapesCue.RTTime                  0\n",
      "ShapesCue.ACC                     1\n",
      "ShapesCue.RT                      0\n",
      "ShapesCue.RESP                  NaN\n",
      "ShapesCue.CRESP                 NaN\n",
      "ShapesCue.OnsetToOnsetTime     3012\n",
      "Shape.OnsetDelay                 12\n",
      "Shape.OnsetTime               84864\n",
      "Shape.DurationError               1\n",
      "Shape.RTTime                  86381\n",
      "Shape.ACC                         0\n",
      "Shape.RT                       1517\n",
      "Shape.RESP                        r\n",
      "Shape.CRESP                     NaN\n",
      "Shape.OnsetToOnsetTime         2008\n",
      "Name: 5, dtype: object\n",
      "FacesList2                         1\n",
      "FacesList2.Cycle                   1\n",
      "FacesList2.Sample                  1\n",
      "FacesCue2.OnsetDelay               8\n",
      "FacesCue2.OnsetTime           183254\n",
      "FacesCue2.DurationError            0\n",
      "FacesCue2.RTTime                   0\n",
      "FacesCue2.ACC                      1\n",
      "FacesCue2.RT                       0\n",
      "FacesCue2.RESP                   NaN\n",
      "FacesCue2.CRESP                  NaN\n",
      "FacesCue2.OnsetToOnsetTime      3012\n",
      "Face2.OnsetDelay                  12\n",
      "Face2.OnsetTime               186266\n",
      "Face2.DurationError                0\n",
      "Face2.RTTime                  187362\n",
      "Face2.ACC                          0\n",
      "Face2.RT                        1096\n",
      "Face2.RESP                         r\n",
      "Face2.CRESP                      NaN\n",
      "Face2.OnsetToOnsetTime          2008\n",
      "Name: 35, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# (2) Test some (potentially problematic) blocks; in sub-001, these are likely still problems: ShapesCue0, FacesCue2\n",
    "print(all_blocks[0]['shape1'])\n",
    "print(all_blocks[2]['face1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           type     onset  OnsetToOnsetTime response      RT  OnsetDelay\n",
      "0    cue-shapes   81852.0            3012.0      NaN     0.0        17.0\n",
      "1        shapes   84864.0            2008.0        r  1517.0        12.0\n",
      "2           ITI   86872.0            1054.0      NaN     0.0         8.0\n",
      "3        shapes   87926.0               0.0        r  1102.0        54.0\n",
      "4           ITI   89934.0            1054.0      NaN     0.0         8.0\n",
      "..          ...       ...               ...      ...     ...         ...\n",
      "247      shapes  499206.0               0.0        g   626.0        54.0\n",
      "248         ITI  501214.0            1055.0      NaN     0.0         8.0\n",
      "249      shapes  502269.0               0.0        g  1235.0        55.0\n",
      "250         ITI  504277.0            1054.0      NaN     0.0         8.0\n",
      "251      shapes  505331.0               0.0        g   685.0        54.0\n",
      "\n",
      "[252 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# (3) Add rows of data iteratively to new dataframe, and write dataframe to \"events\" file\n",
    "columns = ['type', 'onset', 'OnsetToOnsetTime', 'response', 'RT', 'OnsetDelay']\n",
    "events = pd.DataFrame(columns=columns)\n",
    "\n",
    "def appendRowToDf(main_df, block_df, event_type, txt_col):\n",
    "    main_df = main_df.append({'type':event_type,\n",
    "                            'onset':block_df[txt_col + '.OnsetTime'],\n",
    "                            'OnsetToOnsetTime':block_df[txt_col + '.OnsetToOnsetTime'],\n",
    "                            'response':block_df[txt_col + '.RESP'],\n",
    "                            'RT':block_df[txt_col + '.RT'],\n",
    "                            'OnsetDelay':block_df[txt_col + '.OnsetDelay']}, ignore_index = True)\n",
    "    return main_df\n",
    "\n",
    "def appendRowToDfProblem(main_df, block_df, event_type, txt_col):\n",
    "    main_df = main_df.append({'type':event_type,\n",
    "                            'onset':np.nan,\n",
    "                            'OnsetToOnsetTime':np.nan,\n",
    "                            'response':np.nan,\n",
    "                            'RT':np.nan,\n",
    "                            'OnsetDelay':np.nan}, ignore_index = True)\n",
    "    return main_df\n",
    "\n",
    "for i in np.arange(11):\n",
    "    loc1 = i*12\n",
    "    loc2 = loc1+4\n",
    "    loc3 = loc2+1\n",
    "    loc4 = loc3+1\n",
    "    loc5 = loc4+4\n",
    "    loc6 = loc5+1\n",
    "    \n",
    "    if i == 0:\n",
    "        txt = ''\n",
    "    else:\n",
    "        txt = str(i)\n",
    "    \n",
    "    block_df = all_blocks[i]['shape1']\n",
    "    \n",
    "    event_type = 'cue-shapes'\n",
    "    txt_col = 'ShapesCue' + txt\n",
    "    events = appendRowToDf(events, block_df, event_type, txt_col)\n",
    "#     if i in [0]:\n",
    "#         events = appendRowToDfProblem(events, block_df, event_type, txt_col)\n",
    "#     else:\n",
    "#         events = appendRowToDf(events, block_df, event_type, txt_col)\n",
    "    \n",
    "    event_type = 'shapes'\n",
    "    txt_col = 'Shape' + txt\n",
    "    events = appendRowToDf(events, block_df, event_type, txt_col)\n",
    "\n",
    "    # all_blocks[i]['shape5']\n",
    "    for j in range(loc1,loc2+1):\n",
    "        block_df = all_blocks[i]['shape5'].loc[j]\n",
    "        event_type = 'ITI'\n",
    "        txt_col = 'ShapeRest' + txt\n",
    "        events = appendRowToDf(events, block_df, event_type, txt_col)        \n",
    "        event_type = 'shapes'\n",
    "        txt_col = 'ShapesDisplay' + txt\n",
    "        events = appendRowToDf(events, block_df, event_type, txt_col)\n",
    "    \n",
    "    if i < 10:\n",
    "        # all_blocks[i]['face1']\n",
    "        block_df = all_blocks[i]['face1']\n",
    "\n",
    "        event_type = 'cue-faces'\n",
    "        txt_col = 'FacesCue' + txt\n",
    "        events = appendRowToDf(events, block_df, event_type, txt_col)\n",
    "#         if i in [2]:\n",
    "#             events = appendRowToDfProblem(events, block_df, event_type, txt_col)\n",
    "#         else:\n",
    "#             events = appendRowToDf(events, block_df, event_type, txt_col)\n",
    "\n",
    "        event_type = 'faces'\n",
    "        txt_col = 'Face' + txt\n",
    "        events = appendRowToDf(events, block_df, event_type, txt_col)\n",
    "\n",
    "        # all_blocks[i]['face5']\n",
    "        for j in range(loc4,loc5+1):\n",
    "            block_df = all_blocks[i]['face5'].loc[j]\n",
    "            event_type = 'ITI'\n",
    "            txt_col = 'FaceRest' + txt\n",
    "            events = appendRowToDf(events, block_df, event_type, txt_col)        \n",
    "            event_type = 'faces'\n",
    "            txt_col = 'FacesDisplay' + txt\n",
    "            events = appendRowToDf(events, block_df, event_type, txt_col)\n",
    "\n",
    "print(events)\n",
    "events.to_csv(event_files[2], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra unused code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(text_file, 'r', encoding=\"utf8\", errors='ignore') as fo:\n",
    "#     raw_data = fo.readlines()[:20]\n",
    "#     raw_data = [l.rstrip() for l in raw_data]\n",
    "\n",
    "# # Remove unicode characters.\n",
    "# filtered_data = [remove_unicode(row) for row in raw_data]\n",
    "\n",
    "# print('The raw text file (after removing unicode characters):')\n",
    "# for l in filtered_data:\n",
    "#     print(l)\n",
    "# print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
