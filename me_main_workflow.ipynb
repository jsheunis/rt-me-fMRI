{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEUFEP-ME study: Main workflow\n",
    "\n",
    "This notebook contains the workflow required to preprocess and analyse individual and group level data for this study. Multiple subprocesses are called from this main workflow:\n",
    "\n",
    "1. a\n",
    "2. b\n",
    "3. c\n",
    "\n",
    "## Study overview\n",
    "\n",
    "The main purpose of the study is to investigate methods to improve the quality of real-time functional magnetic resonance imaging (fMRI) data. These improvements are for future applications in real-time fMRI neurofeedback, a method where participants are presented with visual feedback of their brain activity while they are inside the MRI scanner, and then asked to regulate the level of feedback. We have developed real-time multi-echo EPI acquisition sequences and processing methods, and this study aims to collect data from volunteers in order to validate these new methods. No neurofeedback is provided.\n",
    "\n",
    "```\n",
    "The scan session will consist of a number of scan sequences, some of which will require you to look at pictures or perform a task, and others just to lie still in the scanner. The total time in the scanner will be around 1 hour, with a break in the middle. Volunteers have to be right-handed, healthy and should have no history of or be under current treatment for psychiatric / neurological conditions. If this inclusion criteria do not fit you, you will unfortunately not be able to participate in the study. Other reasons for not being able to participate include being pregnant or having metal implants.\n",
    "```\n",
    "\n",
    "## Data\n",
    "\n",
    "Per subject, all of the following data were collected during one scan session (all functional scans are multi-echo EPI):\n",
    "\n",
    "| Nr | Name  | Data Type | Description | Acquired Data Format(s) | BIDS Format |\n",
    "| :--- | :--- | :--- | :--- | :--- | :---: |\n",
    "| 1 | T1w | Anatomical MRI | Standard T1-weighted sequence | NIfTI | NIfTI |\n",
    "| 2 | task-rest_run-1_bold | Functional MRI | Resting state | PAR/REC, XML/REC, DICOM | NIfTI |\n",
    "| 3 | task-motor_run-1_bold | Functional MRI | RH Finger tapping | PAR/REC, XML/REC, DICOM | NIfTI |\n",
    "| 4 | task-emotion_run-1_bold | Functional MRI | Hariri task (shape/face matching) | PAR/REC, XML/REC, DICOM | NIfTI |\n",
    "| 5 | task-rest_run-2_bold | Functional MRI | Resting state | PAR/REC, XML/REC, DICOM | NIfTI |\n",
    "| 6 | task-motor_run-2_bold | Functional MRI | Mental motor task - imagined finger tapping | PAR/REC, XML/REC, DICOM | NIfTI |\n",
    "| 7 | task-emotion_run-2_bold | Functional MRI | Mental emotion task - recalling emotional memories | PAR/REC, XML/REC, DICOM | NIfTI |\n",
    "| 8 | Stimulus timing | Peripheral measure | Stimulus and response timing for all tasks, i.e. x4 | Eprime .dat and .txt | .tsv |\n",
    "| 9 | Physiology | Peripheral measure | Cardiac + respiratory traces for all runs, i.e. x6 | Philips \"scanphyslog\" | .tsv |\n",
    "\n",
    "## Data setup\n",
    "\n",
    "See `me_data_setup_workflow.ipynb`\n",
    "\n",
    "## Required packages / software\n",
    "\n",
    "- 1\n",
    "- 2\n",
    "\n",
    "## Data processing plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Study information:\n",
       "\n",
       "The main purpose of the study is to investigate methods to improve the quality of real-time functional magnetic resonance imaging (fMRI) data.\n",
       "These improvements are for future applications in real-time fMRI neurofeedback, a method where participants are presented with visual or other feedback of their brain activity while they are inside the MRI scanner, and then asked to regulate the level of feedback.\n",
       "We have developed real-time multi-echo EPI acquisition sequences and processing methods, and this study aims to collect data from volunteers in order to validate these new methods.\n",
       "\n",
       "\n",
       "### Summarised study design\n",
       "\n",
       "While other possible methodological use cases of this data exist, the acquisition plan (i.e. the types, number and order of scans) was mainly designed to mirror that of an fMRI neurofeedback study, without providing feedback.\n",
       "\n",
       "For rtfMRI-NF studies we require prior information before starting real-time analysis. How do we know where and how to extract the neurofeedback signal? How do we define a template space within which to analyse data in real-time?\n",
       "To get this prior information, we need to acquire and process extra scans before real-time scanning can commence. This translates to a study design with three steps:\n",
       "\n",
       "- RUN 1: Pre-real-time data acquisition\n",
       "- A short period during which to analyse the pre-real-time data\n",
       "- RUN 2: Real-time data acquisition and analysis using prior information\n",
       "\n",
       "We are interested in seeing how real-time multi-echo fMRI can be used to improve the quality of the neurofeedback signal (using several metrics).\n",
       "We want to investigate this on a whole brain level, but we also focus on two regions interesting to the field of rtfMRI-NF: the motor cortex and amygdala.\n",
       "We have designed tasks to elicit BOLD responses in these areas during RUN 1, such that the derived ROIs can be used to analyse region-specific neurofeedback signals during the mentalized versions of the same tasks in RUN 2 .\n",
       "\n",
       "\n",
       "### Research questions and outcomes\n",
       "\n",
       "Three paper approach?\n",
       "\n",
       "1. Data paper:\n",
       "    - gives data a DOI, dataset can be cited when used by other researchers\n",
       "    - fully describing data collection plan and procedure\n",
       "    - sharing BIDS data and materials\n",
       "    - gives summary of ethical approval and GDPR aspects\n",
       "    - running and visualising standard data quality measures\n",
       "    - other?\n",
       "2. Is multi-echo better than single echo for real-time use in ROI-driven neurofeedback, using metrics:\n",
       "    - tSNR (whole brain + ROI voxels + NF signal)\n",
       "    - tCNR (whole brain + ROI voxels + NF signal)\n",
       "    - Carpet plots (whole brain + ROI voxels)\n",
       "    - other?\n",
       "    \n",
       "    Additional goal of providing recommendations for real-time processing steps and shared code for community driven rtme-fMRI tool development\n",
       "3. Exploring the dynamics of combined echoes, T2* and S0 in real-time multi-echo resting state and task fMRI:\n",
       "    - Can we create a better real-time denoising pipeline using multi-echo parameter estimation and their relation to physiology?\n",
       "    - With specific interest in physiology signals\n",
       "    - Possibly looking into partial information decomposition: https://www.biorxiv.org/content/10.1101/596247v3.full\n",
       "    - other exploratory questions?\n",
       "\n",
       "#### Paper 1: Data\n",
       "\n",
       "*tbd*\n",
       "\n",
       "#### Paper 2: Main focus\n",
       "\n",
       "There are several ways to define and test for \"improvement\" of multi-echo vs single echo fMRI for rtfMRI-NF. We plan to investigate the following:\n",
       "\n",
       "1. Does real-time multi-echo combination help recover signal loss and improve temporal signal to noise ratio in:\n",
       "    1. Whole brain\n",
       "    2. Typical dropout areas\n",
       "    3. Regions of interest for neurofeedback (motor cortex and amygdala)\n",
       "    \n",
       "    If so, how much? And how do different combination methods compare?\n",
       "    \n",
       "    - *Create carpet plots of all timeseries*\n",
       "    - *Compare tSNR maps of single echo times eries with variety of combined echo time series*\n",
       "    - *Compare percentage difference in tSNR maps of single echo times eries with variety of combined echo time series*\n",
       "    - *Other possible measures:*\n",
       "        - *DVARS*\n",
       "        -  *?*\n",
       "\n",
       "2. Does real-time multi-echo combination and resulting T2* help improve the contrast to noise ratio for task-based neurofeedback? If so, how much? And how do different time series compare?\n",
       "    \n",
       "    - *Compare percentage signal change of regulation blocks vs baseline blocks within ROIs (all voxels) for all individual time series*\n",
       "    - *Create carpet plots of above* \n",
       "    - *Compare percentage signal change of regulation blocks vs baseline blocks within ROIs (averaged signal, i.e. NF signal) for all individual time series*\n",
       "    \n",
       "\n",
       "#### Paper 3: Later focus\n",
       "\n",
       "*tbd*\n",
       "\n",
       "# Data:\n",
       "\n",
       "Per subject, all of the following data were collected during one scan session (all functional scans are multi-echo EPI):\n",
       "\n",
       "| Nr | Name  | Scan Type | Description | Format |\n",
       "| :--- | :--- | :--- | :--- | :--- |\n",
       "| 1 | T1w | Anatomical | Standard T1-weighted sequence | NIfTI |\n",
       "| 2 | run1_BOLD_rest | Functional | Resting state | PAR/REC, XML/REC, DICOM |\n",
       "| 3 | run1_BOLD_task1 | Functional | Motor - finger tapping | PAR/REC, XML/REC, DICOM |\n",
       "| 4 | run1_BOLD_task2 | Functional | Emotion - shape/face matching | PAR/REC, XML/REC, DICOM |\n",
       "| 5 | run2_BOLD_rest | Functional | Resting state | PAR/REC, XML/REC, DICOM |\n",
       "| 6 | run2_BOLD_task1 | Functional | Motor mental - imagined finger tapping | PAR/REC, XML/REC, DICOM |\n",
       "| 7 | run2_BOLD_task2 | Functional | Emotion mental - recalling emotional memories | PAR/REC, XML/REC, DICOM |\n",
       "| 8 | Stimulus timing | Peripheral measure | Stimulus and response timing for all tasks, i.e. x4 | Eprime .dat and .txt |\n",
       "| 9 | Physiology | Peripheral measure | Cardiac + respiratory traces for all runs, i.e. x6 | Philips \"scanphyslog\" |\n",
       "\n",
       "fMRI parameters:\n",
       " - Philips Achieva 3T\n",
       " - Multi-echo EPI sequence, no multi-band\n",
       " - TR = 2 s\n",
       " - 3 echoes\n",
       " - TE = 14, 28, 42 ms (i.e. echo spacing = 14 ms)\n",
       " - Voxel size 3.5 mm isotropic\n",
       " - In-plane matrix = 64 x 64\n",
       " - Slices = 34\n",
       " - SENSE factor = 2.5\n",
       "\n",
       "# Data preparation\n",
       "\n",
       "See `me_data_setup_workflow.ipynb`\n",
       "\n",
       "For each dataset (i.e. for each subject) we have to:\n",
       "\n",
       "1. Move all files into a machine readable directory structure\n",
       "2. Rename all image files in this directory structure such that BIDS tags are findable\n",
       "3. Convert data to BIDS:\n",
       "    1. Run `bidsify` to convert the image data to BIDS (This includes conversion of PAR/REC to NIfTI using `dcm2niix`; this should also include anonymization using `pydeface`, which doesn't work for some reason)\n",
       "    2. Deface the T1w image using `pydeface`\n",
       "    3. Run eprime conversion script to convert stimilus and response timings to BIDS (need to figure out this format)\n",
       "    4. Run `scanphyslog2bids` (or Matlab script if needed) to convert physiology data to BIDS\n",
       "4. Run the BIDS validator\n",
       "6. Create summary tables and plots using `pybids`\n",
       "\n",
       "IMPORTANT:\n",
       "\n",
       "- [ ] Duplicate full BIDS directory and run processing in duplicate directory, so as not to touch clean BIDS dataset (which is for sharing)\n",
       "\n",
       "# Data analysis\n",
       "\n",
       "Existing / prepared data:\n",
       "- Atlases from SPM Anatomy Toolbox INM7, saved as separate NIfTIs\n",
       "\n",
       "## Open questions\n",
       "\n",
       "- This is strictly speaking an exploratory study and not hypothesis driven. I.e. would not make sense to specify hypothesis and report t and p values. Plan is to calculate improvements i.t.o. percentage difference, and plot distributions using raincloud plots. Sensible?\n",
       "- Should we test for ME improvements in RS? Or only task? Or both and compare?\n",
       "- Where to include drift removal?\n",
       "- How to approach masking for T2* and S0 estimation?\n",
       "- How to define task ROIs\n",
       "- Signal scaling: this is not explicitly applied anywhere except implicitly by SPM in the GLM analysis when creating functional localisers.\n",
       "Should we apply signal scaling (grand mean / something else?) at other points in the pipeline? Are we missing something? \n",
       "- Where to submit?\n",
       "- Data paper?\n",
       "  \n",
       "## Subject-level\n",
       "\n",
       "- Preproc for getting prior estimates of T2* and S0\n",
       "- Preproc for getting functional\n",
       "\n",
       "### Pre-processing: anatomical (RUN 1)\n",
       "\n",
       "1. Anatomical to functional space coregistration, use middle echo first volume as template - SPM12 coregister estimate\n",
       "2. Segment coregistered anatomical image into tissue components - SPM12 unified segmentation\n",
       "    1. Saves inverse transform from subject functional to MNI space\n",
       "3. Coregister relevant regions of interest (from atlases in MNI space) to subject functional space using inverse transfromations\n",
       "4. Reslice all to functional space grid (SPM reslice)\n",
       "\n",
       "\n",
       "### Pre-processing: peripheral data (RUN 1)\n",
       "\n",
       "1. Generate RETROICOR regressors from cardiac and respiratory traces of both runs (run 2 data to be used later) - PhysIO + Matlab\n",
       "\n",
       "\n",
       "### Pre-processing: functional (RUN 1)\n",
       "\n",
       "1. Task region localisation (using only middle echo [TE=28ms] timeseries):\n",
       "    1. Slice time correction\n",
       "    2. 3D volume realignment\n",
       "    3. Calculate framewise displacement from realignment params, select outliers using FD threshold (*which value or percentage?*)\n",
       "    4. Gaussian kernel smoothing (2*voxel size?)\n",
       "    5. GLM analysis incl:\n",
       "        1. AR(1) autoregressive filtering\n",
       "        2. Drift removal / high-pass (SPM cosine basis set)\n",
       "        3. Realignment params [+expansion?]\n",
       "        4. RETROICOR (+HRV, RTV?)\n",
       "        5. FD outlier binary regressor\n",
       "        6. *(global or tissue compartment signals???)*\n",
       "    6. Select t-stat peak within anatomically bound mask (from anatomy toolbox ROI)\n",
       "    7. Select N amount of voxels neighbouring peak voxel ==> ROI for real-time use\n",
       "\n",
       "2. T2*, S0, tSNR calculation from `run1_BOLD_rest` dataset (*is this sensible, as opposed to using RUN 1 task data?*):\n",
       "    1. Slice time correction on all three echo timeseries\n",
       "    2. 3D volume realignment on middle echo timeseries\n",
       "    3. Apply rigid body transformations from middle echo realignment parameters to echo 1 and echo 3 timeseries\n",
       "    6. T2* and S0 estimation (*check steps of tedana*):\n",
       "        1. *How to mask?*\n",
       "        2. Calculate timeseries average\n",
       "        3. Estimate T2* and S0 using log-linear fit of mono-exponential decay model\n",
       "        4. *Threshold?*\n",
       "    4. *Drift removal?*\n",
       "    5. tSNR calculation:\n",
       "        1. *How to mask?*\n",
       "        2. Mean / stddev\n",
       "    \n",
       "\n",
       "### Real-time processing (RUN 2)\n",
       "\n",
       "Do the following per time-point:\n",
       "\n",
       "1. Slice time correction on all three echoes\n",
       "2. 3D volume realignment on middle echo\n",
       "3. Apply rigid body transformations from middle echo realignment parameters to echo 1 and echo 3\n",
       "4. *Drift removal?*\n",
       "5. Real-time T2* and S0 estimation:\n",
       "    1. *How to mask?*\n",
       "    3. Estimate T2* and S0 from current timepoint echoes using log-linear fit of mono-exponential decay model\n",
       "    4. *Threshold?*\n",
       "6. Multi-echo combination:\n",
       "    1. Linearly-weighted (*and/or summed?*)\n",
       "    2. Pre-tSNR-weighted\n",
       "    3. Pre-T2*-weighted\n",
       "    4. Real-time T2*-weighted\n",
       "7. Gaussian kernel smoothing (2 x voxel size?) of echo combinations, of T2* and of middle echo.\n",
       "8. Calculate neurofeedback signal using OpenNFT methodology:\n",
       "\t1. Mask using \n",
       "\t2. Average within mask\n",
       "\t3. Incremental GLM a la OpenNFT, includes:\n",
       "\t    1. Low-pass filter / *drift removal?*\n",
       "\t    2. AR(1) filter\n",
       "\t    3. Motion parameters\n",
       "\t    4. *what else?*\n",
       "\t4. *(include Kalman filter? don't think we should)*\n",
       "\t5. NFB trace (before and after OpenNFT scaling)\n",
       "\n",
       "### Post real-time analysis:\n",
       "\n",
       "*Is this where signal scaling / normalisation needs to come in?*\n",
       "\n",
       "1. tSNR maps for following timeseries:\n",
       "    1. Middle echo\n",
       "    2. Combined: Linearly-weighted (*and/or summed?*)\n",
       "    3. Combined: Pre-tSNR-weighted\n",
       "    4. Combined: Pre-T2*-weighted\n",
       "    5. Combined: Real-time T2*-weighted\n",
       "    6. T2*\n",
       "2. Percentage difference maps for tSNR from middle echo to:\n",
       "    1. Combined: Linearly-weighted (*and/or summed?*)\n",
       "    2. Combined: Pre-tSNR-weighted\n",
       "    3. Combined: Pre-T2*-weighted\n",
       "    4. Combined: Real-time T2*-weighted\n",
       "3. Percentage difference maps for tSNR from middle echo to:\n",
       "    1. Combined: Linearly-weighted (*and/or summed?*)\n",
       "    2. Combined: Pre-tSNR-weighted\n",
       "    3. Combined: Pre-T2*-weighted\n",
       "    4. Combined: Real-time T2*-weighted\n",
       "3. Extract measures for ROIs\n",
       "\n",
       "\n",
       "## Group level\n",
       "\n",
       "WHAT TO COMPARE:\n",
       "- Single (middle) echo vs. echo combination (various methods) vs R2star\n",
       "- Metrics and visualisation:\n",
       "\t- tSNR (rs brain + task brain + task ROIs)\n",
       "\t- tCNR (BOLD percentage signal change; rs brain + task brain + task ROIs)\n",
       "\t- PSC brain maps and raincloudlots of above\n",
       "\t- DVARS (rs brain + task brain + task ROIs)\n",
       "\t- ThePlot whole brain + task ROI\n",
       "\t- physiology between conditions\n",
       "\n",
       "\n",
       "# Quality control\n",
       "\n",
       "*Idea is for this to be reported as part of the Data Paper*\n",
       "\n",
       "- MRIQC from BIDS (derivatives)\n",
       "- Own quality checker scripts\n",
       "- Extra metrics to report:\n",
       "\t- physiology between conditions\n",
       "- Real-time quality control metrics (from rtQC):\n",
       "\t- FD\n",
       "\t- other?\n",
       "\n",
       "# TODO:\n",
       "- [x] send processing plan to cesar + sveta + lydia + Jaap\n",
       "- [ ] Get paper+code of Soroosh Insights into DVARS\n",
       "- [ ] Pybids for handling BIDS datasets\n",
       "\n",
       "\n",
       "# IDEAS:\n",
       "- jupyter notebook with automated pipeline to get 3d printed file from t1 weighted, or something, using: https://github.com/bernhard-42/jupyter-cadquery/\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "mdfile = '/Users/jheunis/Documents/PYTHON/rtme-fMRI/pipeline_description.md'\n",
    "\n",
    "with open(mdfile, 'r') as fh:\n",
    "    content = fh.read()\n",
    "\n",
    "display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import bidsify\n",
    "import pydeface\n",
    "import pandas as pd\n",
    "import json\n",
    "from bids_validator import BIDSValidator\n",
    "from convert_eprime.convert import text_to_csv\n",
    "from scanphyslog2bids.core import PhilipsPhysioLog\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: initialize variables, directories, filenames, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependent on structure and filenames in current data on external drive\n",
    "data_dir = '/Volumes/Stephan_WD/NEUFEPME_data/'\n",
    "new_data_dir = '/Volumes/Stephan_WD/NEUFEPME_data/NEUFEPME_data_new/'\n",
    "org_data_dir = '/Volumes/Stephan_WD/NEUFEPME_data_organised/'\n",
    "new_org_data_dir = org_data_dir + 'new/'\n",
    "bids_data_dir = '/Volumes/Stephan_WD/NEUFEPME_data_BIDS/'\n",
    "bids_deriv_data_dir = '/Volumes/Stephan_WD/NEUFEPME_data_BIDS/derivatives/'\n",
    "eprime_data_dir = '/Volumes/Stephan_WD/NEUFEPME_data_eprime/'\n",
    "preproc_dir = os.path.join(bids_deriv_data_dir, 'subjectPreProcSPM12')\n",
    "\n",
    "# Specify MATLAB code directory\n",
    "matlab_dir = '/Users/jheunis/Documents/MATLAB'\n",
    "# Specify SPM installation directory\n",
    "spm_dir = '/Users/jheunis/Documents/MATLAB/spm12'\n",
    "# Specify directory with main matlab scripts\n",
    "proc_dir = '/Users/jheunis/Documents/PYTHON/rtme-fMRI/matlab'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?1h\u001b=\n",
      "                            < M A T L A B (R) >\n",
      "                  Copyright 1984-2016 The MathWorks, Inc.\n",
      "                   R2016b (9.1.0.441655) 64-bit (maci64)\n",
      "                             September 7, 2016\n",
      "\n",
      " \n",
      "For online documentation, see http://www.mathworks.com/support\n",
      "For product information, visit www.mathworks.com.\n",
      " \n",
      ">> \n",
      ">> \n",
      ">> \u001b[?1h\u001b=\n",
      "                            < M A T L A B (R) >\n",
      "                  Copyright 1984-2016 The MathWorks, Inc.\n",
      "                   R2016b (9.1.0.441655) 64-bit (maci64)\n",
      "                             September 7, 2016\n",
      "\n",
      " \n",
      "For online documentation, see http://www.mathworks.com/support\n",
      "For product information, visit www.mathworks.com.\n",
      " \n",
      ">> \n",
      "\n",
      ">> "
     ]
    }
   ],
   "source": [
    "!matlab -nodisplay -nojvm -r \"addpath('$spm_dir')\"\n",
    "!matlab -nodisplay -nojvm -r \"addpath('$proc_dir')\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: preparation for structural-functional preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy BIDS data required for struct-func-preproc to relevant BIDS deriv directory 'subjectPreProcSPM12'\n",
    "os.chdir(bids_data_dir)\n",
    "all_subs = next(os.walk(bids_data_dir))[1]\n",
    "print(all_subs)\n",
    "for i, sub in enumerate(all_subs):\n",
    "    print('{} - {}'.format(i, sub))\n",
    "    sub_dir = os.path.join(bids_data_dir, sub)\n",
    "    src = sub_dir    \n",
    "    dst = os.path.join(preproc_dir, sub)\n",
    "    if not os.path.exists(dst):\n",
    "        shutil.copytree(src, dst)\n",
    "    else:\n",
    "        print('Already copied')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: structural-functional preprocessing A\n",
    "\n",
    "1. Anatomical to functional space coregistration, use middle echo first volume as template - SPM12 coregister estimate\n",
    "2. Segment coregistered anatomical image into tissue components - SPM12 unified segmentation\n",
    "    1. Saves inverse transform from subject functional to MNI space\n",
    "3. Coregister relevant regions of interest (from atlases in MNI space) to subject functional space using inverse transfromations\n",
    "4. Reslice all to functional space grid (SPM reslice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(preproc_dir)\n",
    "all_subs = next(os.walk(bids_data_dir))[1]\n",
    "print(all_subs)\n",
    "for i, sub in enumerate(all_subs):\n",
    "    \n",
    "# !matlab -r -nodisplay -nojvm '//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dash site stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
